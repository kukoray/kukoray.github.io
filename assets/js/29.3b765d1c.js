(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{450:function(t,a,r){"use strict";r.r(a);var e=r(65),s=Object(e.a)({},(function(){var t=this,a=t.$createElement,r=t._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h1",{attrs:{id:"机器学习数学基础"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#机器学习数学基础"}},[t._v("#")]),t._v(" 机器学习数学基础")]),t._v(" "),r("img",{staticStyle:{zoom:"80%"},attrs:{src:"https://s2.loli.net/2022/04/26/3Zaoz12emWn4tpy.png",alt:"image-20220426213634626"}}),t._v(" "),r("h2",{attrs:{id:"协方差"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#协方差"}},[t._v("#")]),t._v(" 协方差")]),t._v(" "),r("p",[t._v("​\t\t"),r("strong",[t._v("协方差")]),t._v("（Covariance）在"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E6%A6%82%E7%8E%87%E8%AE%BA/829122",target:"_blank",rel:"noopener noreferrer"}},[t._v("概率论"),r("OutboundLink")],1),t._v("和"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E7%BB%9F%E8%AE%A1%E5%AD%A6/1175",target:"_blank",rel:"noopener noreferrer"}},[t._v("统计学"),r("OutboundLink")],1),t._v("中用于衡量两个变量的总体"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E8%AF%AF%E5%B7%AE/738024",target:"_blank",rel:"noopener noreferrer"}},[t._v("误差"),r("OutboundLink")],1),t._v("。而"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE/3108412",target:"_blank",rel:"noopener noreferrer"}},[r("strong",[t._v("方差")]),r("OutboundLink")],1),t._v("是"),r("strong",[t._v("协方差的一种特殊情况")]),t._v("，即当两个变量是相同的情况。")]),t._v(" "),r("p",[t._v("​\t\t协方差表示的是两个变量的总体的"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E8%AF%AF%E5%B7%AE/738024",target:"_blank",rel:"noopener noreferrer"}},[t._v("误差"),r("OutboundLink")],1),t._v("，这与只表示一个变量误差的"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE/3108412",target:"_blank",rel:"noopener noreferrer"}},[t._v("方差"),r("OutboundLink")],1),t._v("不同。如果两个"),r("a",{attrs:{href:"https://baike.baidu.com/item/%E5%8F%98%E9%87%8F/5271",target:"_blank",rel:"noopener noreferrer"}},[t._v("变量"),r("OutboundLink")],1),t._v("的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。")]),t._v(" "),r("p",[r("img",{attrs:{src:"https://bkimg.cdn.bcebos.com/formula/bd5a49802fd29c7a58bbba490f66ee93.svg",alt:"img"}})]),t._v(" "),r("p",[t._v("​\t\t如果"),r("em",[t._v("X")]),t._v("与"),r("em",[t._v("Y")]),t._v("是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足"),r("em",[t._v("E")]),t._v("["),r("em",[t._v("XY")]),t._v("]="),r("em",[t._v("E")]),t._v("["),r("em",[t._v("X")]),t._v("]"),r("em",[t._v("E")]),t._v("["),r("em",[t._v("Y")]),t._v("]。")]),t._v(" "),r("h2",{attrs:{id:"概率基础"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#概率基础"}},[t._v("#")]),t._v(" 概率基础")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://blog.csdn.net/gcheney/article/details/108442861",target:"_blank",rel:"noopener noreferrer"}},[t._v("概率基础最好的文章"),r("OutboundLink")],1)]),t._v(" "),r("h3",{attrs:{id:"概率和统计"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#概率和统计"}},[t._v("#")]),t._v(" 概率和统计")]),t._v(" "),r("ul",[r("li",[t._v("概率：已知模型和参数（生成数据的过程），推数据（结果）。（机器学习模型的"),r("strong",[t._v("应用")]),t._v("）")]),t._v(" "),r("li",[t._v("统计：已知数据，推模型和参数。（机器学习模型的"),r("strong",[t._v("训练过程")]),t._v("）")])]),t._v(" "),r("h3",{attrs:{id:"贝叶斯公式"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#贝叶斯公式"}},[t._v("#")]),t._v(" 贝叶斯公式")]),t._v(" "),r("p",[r("img",{attrs:{src:"https://s2.loli.net/2023/04/07/GPIyTu5gvsaFkKO.png",alt:"image-20230407195006425"}})]),t._v(" "),r("p",[t._v("深入理解：")]),t._v(" "),r("p",[t._v("例子：A是车被砸，B是车发出警报")]),t._v(" "),r("p",[t._v("那么我们先要算的是，左式  = "),r("strong",[t._v("车发出警报，车被砸了的可能性？")])]),t._v(" "),r("p",[t._v("右式  =  "),r("strong",[t._v("【车被砸，引起警报】 除以  【车发出警报】")])]),t._v(" "),r("p",[r("strong",[t._v("从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。你的车响了，不一定是被砸了，也有可能就是隔壁小朋友踢了一脚。")])]),t._v(" "),r("h3",{attrs:{id:"似然函数和概率函数"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#似然函数和概率函数"}},[t._v("#")]),t._v(" 似然函数和概率函数")]),t._v(" "),r("p",[t._v("在统计里面，似然函数(likelihood function)和概率函数(probability function)是两个不同的概念（其实也很相近就是了）。\n　　\n之前我们说到：\n　　"),r("strong",[t._v("概率是已知模型和参数（生成数据的过程），推数据（结果）。\n　　统计是已知数据（结果），推模型和参数（生成数据的过程）。")]),t._v("\n　　对于这个函数：P ( x ∣ θ )。输入有两个：x 表示某一个具体的数据；θ 表示模型的参数。")]),t._v(" "),r("p",[t._v("如果θ 是已知确定的，x 是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x ，其出现概率是多少。")]),t._v(" "),r("p",[t._v("如果x 是已知确定的，θ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x 这个样本点的概率是多少。")]),t._v(" "),r("h3",{attrs:{id:"极大似然估计mle"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#极大似然估计mle"}},[t._v("#")]),t._v(" 极大似然估计MLE")]),t._v(" "),r("p",[t._v("首先这是个统计问题，已知数据，求参数（概率参数）。")]),t._v(" "),r("p",[t._v("根据统计的现象，去求参数θ，使得似然函数P(x|θ)最大。")]),t._v(" "),r("p",[r("strong",[t._v("说白了，就是似然函数越大，这个参数θ，越可能接近于最终的真实值（假设有真实值存在）")])]),t._v(" "),r("p",[t._v("一般当样例数足够大时，极大似然估计得出的θ，我们会默认把他当做真实值！")]),t._v(" "),r("h3",{attrs:{id:"最大后验概率估计map"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#最大后验概率估计map"}},[t._v("#")]),t._v(" 最大后验概率估计MAP")]),t._v(" "),r("p",[t._v("这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计")]),t._v(" "),r("p",[r("strong",[t._v("最大后验概率估计则是想求θ ，使 P(X|θ)P(θ)最大，求得的θ 不单单让似然函数大，θ 自己出现的先验概率也得大")]),t._v(" 。（这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法）")]),t._v(" "),r("p",[r("img",{attrs:{src:"https://s2.loli.net/2023/04/07/Invz96lrhZYqDV7.png",alt:"image-20230407195027833"}})]),t._v(" "),r("p",[t._v("最大后验概率估计  是 极大似然估计 和 贝叶斯网络的结合")]),t._v(" "),r("p",[t._v("可以理解为，引入了先验概率，让实验结果没那么可信！但是如果说实验结果的数据量特别大，那么也会偏向于实验得出来的结果，而不是先验概率。")]),t._v(" "),r("h3",{attrs:{id:"kl散度"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kl散度"}},[t._v("#")]),t._v(" KL散度")]),t._v(" "),r("p",[t._v("是两个概率分布 P和Q 的相似性")]),t._v(" "),r("h3",{attrs:{id:"js散度"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#js散度"}},[t._v("#")]),t._v(" JS散度")]),t._v(" "),r("h3",{attrs:{id:"wasserstein距离"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wasserstein距离"}},[t._v("#")]),t._v(" wasserstein距离")]),t._v(" "),r("h2",{attrs:{id:"欧式空间和黎曼空间"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#欧式空间和黎曼空间"}},[t._v("#")]),t._v(" 欧式空间和黎曼空间")]),t._v(" "),r("h3",{attrs:{id:"hessian-matrix"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#hessian-matrix"}},[t._v("#")]),t._v(" hessian matrix")]),t._v(" "),r("p",[t._v("海森矩阵")]),t._v(" "),r("h3",{attrs:{id:"fisher-information-matrix"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#fisher-information-matrix"}},[t._v("#")]),t._v(" fisher information matrix")]),t._v(" "),r("p",[t._v("费舍尔信息矩阵")]),t._v(" "),r("h2",{attrs:{id:"凸优化问题"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#凸优化问题"}},[t._v("#")]),t._v(" 凸优化问题")])])}),[],!1,null,null,null);a.default=s.exports}}]);