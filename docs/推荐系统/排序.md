# 排序

- [多目标排序模型.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619021423-075c82b6-d732-468c-9d4a-f09aa75acbcd.pdf)

- [Multi-gate Mixture-of-Experts MMoE.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619021381-5a7ffcf8-bc7a-4d4e-ae5a-d526be46f7aa.pdf)

- [预估分数融合.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619019658-0aac3bde-6f79-4827-a7de-2d7f19ca47ff.pdf)

- [播放时长建模.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619020125-5800d032-1547-4090-9db8-6803c77418b4.pdf)

- [推荐系统的特征.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619019750-f3568649-f28b-42f0-94e8-861d0b9b1e49.pdf)

- [粗排三塔模型.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/101969/1676619020734-069bd880-e217-46fc-88ba-93ced388841a.pdf)

## 多目标排序模型

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618588556-a287df85-89af-406c-bbfb-96172d603fcb.png)

本节内容集中在粗排和精排，它们的原理基本相同。

### 用户—笔记的交互

排序的主要依据是用户对笔记的兴趣，而兴趣都反映在 用户—笔记 的交互中。

-  对于每篇笔记，系统记录： 

- - 曝光次数（number of impressions）

- - 点击次数（number of clicks）

- - 点赞次数（number of likes）

- - 收藏次数（number of collects）

- - 转发次数（number of shares）

-  点击率 = 点击次数 / 曝光次数 

-  点赞率 = 点赞次数 / 点击次数 

-  收藏率 = 收藏次数 / 点击次数 

-  转发率 = 转发次数 / 点击次数 

-  排序的依据 

- - 排序模型预估点击率、点赞率、收藏率、转发率等多种分数

- - 融合这些预估分数（比如加权和，一般权重的值都是做A/B测试得到的）

- - 根据融合的分数做排序、截断

### 多目标模型

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618649405-def02245-e0c8-4473-a983-8550479d93b8.png)

- 统计特征包括"用户统计特征"和"物品统计特征"

- "场景特征" 是随着用户请求传过来的

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618662752-9c5335a7-b738-48c8-bb32-140d9d0448e6.png)

-  训练：让预估值接近真实目标值 ，每一个都是一个二元分类任务

- -  总的损失函数： ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Csum%5E4_%7Bi%3D1%7D%7B%CE%B1_i%C2%B7%5Crm%7BCrossEntropy%7D(y_i%2Cp_i)%7D) 

- -  对损失函数求梯度，做梯度下降更新参数 

- -  困难：类别不平衡，即正样本数量显著少于负样本 

- - - 每 100 次曝光，约有 10 次点击、90 次无点击

- - - 每 100 次点击，约有 10 次收藏、90 次无收藏

- - -  注：不是小红书的真实数据

- -  解决方案：负样本降采样（down-sampling） 

- - - 保留一小部分负样本

- - - 让正负样本数量平衡，节约计算量

### 预估值校准

做了降采样后训练出的预估点击率会大于真实点击率。

-  正样本、负样本数量为 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n_%2B) 和 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n_-) 

-  对负样本做降采样，抛弃一部分负样本 

-  使用 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Calpha%20%C2%B7n_-) 个负样本，![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Calpha%20%5Cin(0%2C%201)) 是采样率 

-  由于负样本变少，预估点击率大于真实点击率 

-  校准公式： 

- -  真实点击率：![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Btrue%7D%3D%5Cfrac%7Bn_%2B%7D%7Bn_%2B%2Bn_-%7D)（期望） 

- -  预估点击率：![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bpred%7D%3D%5Cfrac%7Bn_%2B%7D%7Bn_%2B%2B%5Calpha%20%C2%B7n_-%7D)（期望） 

- -  由上面两个等式可推导得到校准公式[1]： ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Btrue%7D%3D%5Cfrac%7B%5Calpha%20%C2%B7p_%7Bpred%7D%7D%7B(1-p_%7Bpred%7D)%2B%5Calpha%20%C2%B7p_%7Bpred%7D%7D%0A) 

参考文献：1. Xinran He et al. Practical lessons from predicting clicks on ads at Facebook. In the 8th International Workshop on Data Mining for Online Advertising.

## Multi-gate Mixture-of-Experts (MMoE) 专家神经网络

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618703804-6887a861-6fd6-4ddc-87f4-2f200da00d63.png)

- 三个神经网络结构相同，但是不共享参数

- 专家神经网络的数量是超参数，实践中通常用 4 个或 8 个

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618711411-50a618c0-3c1c-4db9-ac4b-e8a6f16d3bb8.png)

-  把特征向量输入左侧的神经网络，再通过 Softmax 输出 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_1%2Cp_2%2Cp_3) 分别对应 3 个专家神经网络 

- - 用 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_1%2Cp_2%2Cp_3) 作为权重，对 3 个专家神经网络的输出 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?x_1%2Cx_2%2Cx_3) 进行加权平均

-  采取同样方法，将特征向量输入右侧的神经网络，得到的 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?q_1%2Cq_2%2Cq_3) 可以与专家神经网络的输出组成另一个预估值的输入 

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618720917-0f12535c-3e71-41bb-840c-3dc17bab68b6.png)

### 极化现象（Polarization）

专家神经网络在实践中的问题。

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618730710-ae5e53f7-23ed-443e-ad2d-cc3e8fa8d90b.png)

-  解决极化问题 

- -  如果有 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 个“专家”，那么每个 softmax 的输入和输出都是 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 维向量 

- -  在训练时，对 softmax 的输出使用 dropout 

- - -  Softmax 输出的 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 个数值被 mask 的概率都是 10% 

- - -  每个“专家”被随机丢弃的概率都是 10% 

- - - - 由于每个“专家”都可能被丢弃，神经网络就会尽量避免极化的发生

### 参考文献

- Google 的论文[1] 提出 MMoE 模型

- YouTube 的论文[2] 提出极化问题的解决方案

参考文献：

1. Jiaqi Ma et al. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. In KDD, 2018.

1. Zhe Zhao et al. Recommending What Video to Watch Next: A Multitask Ranking System. In RecSys, 2019.

PS：并不一定用上 MMoE 就一定有提升。造成的原因可能是实现不够好或不适用于特定业务。

## 预估分数的融合

-  简单的加权和 

- - ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bclick%7D%2Bw_1%C2%B7p_%7Blike%7D%2Bw_2%C2%B7p_%7Bcollect%7D%2B...)

-  点击率乘以其他项的加权和 

- -  ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bclick%7D%C2%B7(1%2Bw_1%C2%B7p_%7Blike%7D%2Bw_2%C2%B7p_%7Bcollect%7D%2B...)) 

- - - ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bclick%7D%3D%5Cfrac%7B%5C%23%E7%82%B9%E5%87%BB%7D%7B%5C%23%E6%9B%9D%E5%85%89%7D)，![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Blike%7D%3D%5Cfrac%7B%5C%23%E7%82%B9%E8%B5%9E%7D%7B%5C%23%E7%82%B9%E5%87%BB%7D)

- - - 所以 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bclick%7D%C2%B7p_%7Blike%7D%3D%5Cfrac%7B%5C%23%E7%82%B9%E8%B5%9E%7D%7B%5C%23%E6%9B%9D%E5%85%89%7D)

-  海外某短视频 APP 的融分公式 

- - ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?(1%2Bw_%7B1%7D%5Ccdot%20p_%7Btime%7D)%5E%7B%5Calpha_%7B1%7D%7D%5C%20%5Ccdot%5C%20%5C%20(1%2Bw_%7B2%7D%5Ccdot%20p_%7Blike%7D)%5E%7B%5Calpha_%7B2%7D%7D%5C%20%5Ccdots)

-  国内某短视频 APP （老铁）的融分公式 

- -  根据预估时长 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Btime%7D)，对 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 篇候选视频做排序 

- -  如果某视频排名第 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?r_%7Btime%7D)，则它得分 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cfrac%7B1%7D%7Br%5E%5Calpha%20_%7Btime%7D%20%2B%5Cbeta%7D) 

- -  对点击、点赞、转发、评论等预估分数做类似处理 

- -  最终融合分数： ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cfrac%7Bw_%7B1%7D%7D%7Br_%7B%5Cmathrm%7Btime%7D%7D%5E%7B%5Calpha_%7B1%7D%7D%2B%5Cbeta_%7B1%7D%7D%5C%20%2B%5C%20%5Cfrac%7Bw_%7B2%7D%7D%7Br_%7B%5Cmathrm%7Bclick%7D%7D%5E%7B%5Calpha_%7B2%7D%7D%2B%5Cbeta_%7B2%7D%7D%5C%20%2B%5C%20%5Cfrac%7Bw_%7B3%7D%7D%7Br_%7B%5Cmathrm%7Blike%7D%7D%5E%7B%5Calpha_%7B3%7D%7D%2B%5Cbeta_%7B3%7D%7D%5C%20%2B%5C%20%5Ccdots%0A) 

- - - 公式特点在于 —— 使用预估的排名

-  某电商的融分公式 

- -  电商的转化流程：曝光 → 点击 → 加购物车 → 付款 

- -  模型预估：![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bclick%7D)、![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bcart%7D)、![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bpay%7D) 

- -  最终融合分数： ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7B%5Cmathrm%7Bcilck%7D%7D%5E%7B%5Calpha_%7B1%7D%7D%5C%20%5Ctimes%5C%20%5C%20p_%7B%5Cmathrm%7Bcart%7D%7D%5E%7B%5Calpha_%7B2%7D%7D%5C%20%5Ctimes%5C%20%5C%20p_%7B%5Cmathrm%7Bpay%7D%7D%5E%7B%5Calpha_%7B3%7D%7D%5C%20%5Ctimes%5C%20%5Cmathrm%7Bprice%7D%5E%7B%5Calpha_%7B4%7D%7D%0A) 

- - - 假如 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Calpha_%7B1%7D%3D%5Calpha_%7B2%7D%3D%5Calpha_%7B3%7D%3D%5Calpha_%7B4%7D%3D1) 那该公式就是电商的营收，有明确的物理意义

## 视频播放建模

### 视频播放时长

-  图文 vs. 视频 

- -  图文笔记排序的主要依据：点击、点赞、收藏、转发、评论...... 

- -  视频排序的依据还有播放时长和完播 

- - - 对于视频来说，播放时长与完播的重要性大于点击

- -  直接用回归拟合播放时长效果不好。建议用 YouTube 的时长建模[1] 

参考文献：1.Paul Covington, Jay Adams, & Emre Sargin. Deep Neural Networks for YouTube Recommendations. In RecSys, 2016.

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618787183-dc740b17-0282-400f-a56f-2eaf91180881.png)

- 每个全连接层对应一个目标，假设最右边的输出对应播放时长 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?z)

- 对 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?z) 做 Sigmoid 变换得到 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p)，然后让 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p) 拟合 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?y)，它们的交叉熵作为损失函数

- ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?y) 是我们定义的，其中的 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?t) 是用户实际观看时长，![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?t) 越大则 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?y) 越大

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618796083-8744829e-df29-4287-b1f1-e933856b20f8.png)

-  观察公式发现，如果 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p%3Dy)，那么 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cexp%7B(z)%7D%3Dt) 

-  即 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cexp%7B(z)%7D) 就是播放时长的预估值 

-  总结视频播放时长建模 

- -  把最后一个全连接层的输出记作 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?z)。设 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p%3Dsigmoid(z)) 

- -  实际观测的播放时长记作 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?t)。（如果没有点击，则 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?t%20%3D%200)） 

- -  做训练：最小化交叉熵损失 

  - $$
    -\left(\frac{t}{1+t} \cdot \log p+\frac{1}{1+t} \cdot \log (1-p)\right)
    $$

- - - 实践中可以去掉分母 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?1%2Bt)，就等于给损失函数做加权，权重是播放时长

- -  做推理：把 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?exp(z)) 作为播放时长的预估 

- -  最终把 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?exp(z)) 作为融分公式中的一项 

### 视频完播

-  回归方法 

- - 例：视频长度 10 分钟，实际播放 4 分钟，则实际播放率为 𝑦 = 0.4

- - 让预估播放率 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p) 拟合 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?y)：![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Ctextstyle%7Bloss%7D%3Dy%5Ccdot%5Clog%20p%2B(1-y)%5Ccdot%5Clog(1-p))

- - 线上预估完播率，模型输出 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p) = 0.73，意思是预计播放 73%

-  二元分类方法 

- -  自定义完播指标，比如完播 80% 

- -  例：视频长度 10 分钟，播放 > 8 分钟作为正样本，播放 < 8 分钟作为负样本 

- -  做二元分类训练模型：播放 > 80% vs 播放 < 80% 

- -  线上预估完播率，模型输出 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p) = 0.73，意思是 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cmathbb%7BP%7D(%E6%92%AD%E6%94%BE%3E80%5C%25)%3D0.73%0A) 

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618814168-c619b559-4981-4064-aa6c-a10a27979030.png)

-  实际中不能直接把预估的完播率用到融分公式（why？） 

- - 因为视频越长，完播率越低

- - 所以直接使用预估完播率，会有利于短视频，而对长视频不公平

-  线上预估完播率，然后做调整：![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bfinish%7D%3D%5Cfrac%7B%E9%A2%84%E4%BC%B0%E5%AE%8C%E6%92%AD%E7%8E%87%7D%7Bf(%E8%A7%86%E9%A2%91%E9%95%BF%E5%BA%A6)%7D) 

- - ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?f) 就是上图中的拟合曲线

-  把 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bfinish%7D) 作为融分公式中的一项 

## 排序模型的特征

### 特征

-  用户画像（User Profile） 

- -  用户 ID（在召回、排序中做 embedding） 

- - - 用户 ID 本身不携带任何信息，但模型学到的 ID embedding 对召回和排序有很重要的影响

- -  人口统计学属性：性别、年龄 

- -  账号信息：新老、活跃度...... 

- - - 模型需要专门针对 新用户 和 低活跃 用户做优化

- -  感兴趣的类目、关键词、品牌 

-  物品画像（Item Profile） 

- -  物品 ID（在召回、排序中做 embedding） 

- -  发布时间（或者年龄） 

- -  GeoHash（经纬度编码）、所在城市 

- -  标题、类目、关键词、品牌...... 

- -  字数、图片数、视频清晰度、标签数...... 

- - - 反映笔记的质量

- -  内容信息量、图片美学...... 

- - - 事先用人工标注的数据训练 NLP 和 CV 模型，然后用模型打分

-  用户统计特征 

- -  用户最近 30 天（7 天、1 天、1 小时）的曝光数、点击数、点赞数、收藏数...... 

- - - 划分各种时间粒度，可以反映用户的 实时、短期、中长期 兴趣

- -  按照笔记图文/视频分桶。（比如最近 7 天，该用户对图文笔记的点击率、对视频笔记的点击率） 

- - - 反映用户对两类笔记的偏好

- -  按照笔记类目分桶。（比如最近 30 天，用户对美妆笔记的点击率、对美食笔记的点击率、对科技数码笔记的点击率） 

- - - 反映用户对哪个类目更感兴趣

-  笔记统计特征 

- -  笔记最近 30 天（7 天、1 天、1 小时）的曝光数、点击数、点赞数、收藏数...... 

- - - 划分时间粒度，可以提前发现哪些笔记过时了

- -  按照用户性别分桶、按照用户年龄分桶...... 

- -  作者特征： 

- - - 发布笔记数

- - - 粉丝数

- - - 消费指标（曝光数、点击数、点赞数、收藏数）

-  场景特征（Context） 

- -  用户定位 GeoHash（经纬度编码）、城市 

- -  当前时刻（分段，做 embedding） 

- - - 一个人在同一天不同时刻的兴趣是变化的

- - - 而且可以反推用户是在上班路上、公司、家里

- -  是否是周末、是否是节假日 

- -  手机品牌、手机型号、操作系统 

- - - 安卓用户和苹果用户的 点击率、点赞率 等数据差异很大

-  特征处理 

- -  离散特征：做 embedding 

- - - 用户 ID、笔记 ID、作者 ID

- - - 类目、关键词、城市、手机品牌

- -  连续特征： 

- - -  做分桶，变成离散特征 

- - - - 年龄、笔记字数、视频长度

- - -  其他变换 

- - - - 曝光数、点击数、点赞数等数值做 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Clog%7B(1%2Bx)%7D)

- - - - 转化为点击率、点赞率等值，并做平滑

-  特征覆盖率 

- -  很多特征无法覆盖 100% 样本 

- -  例：很多用户不填年龄，因此用户年龄特征的覆盖率远小于 100% 

- -  例：很多用户设置隐私权限，APP 不能获得用户地理定位，因此场景特征有缺失 

- -  提高特征覆盖率，可以让精排模型更准 

- - - 想各种办法提高特征覆盖率，并考虑特征缺失时默认值如何设置

### 数据服务

1. 用户画像（User Profile）

1. 物品画像（Item Profile）

1. 统计数据

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618865307-41521df4-4932-4260-9bf5-3c40737ec02b.png)

-  用户画像数据库压力小（每次只读 1 个用户），物品画像数据库压力非常大（每次读几千个物品） 

- - 工程实现时，用户画像中的特征可以很多很大，但尽量不往物品画像中塞很大的向量

-  由于用户和物品画像较为静态，甚至可以把用户和物品画像缓存在排序服务器本地，加速读取 

-  收集了排序所需特征后，将特征打包发给 TF Serving，Tensorflow 给笔记打分并把分数返回排序服务器 

-  排序服务器依据融合的分数、多样性分数、业务规则等给笔记排序，并把排名最高的几十篇返回主服务器 

## 粗排

前面介绍的模型主要用于精排，本节介绍怎么做粗排。

### 粗排 vs 精排

-  粗排 

- - 给几千篇笔记打分

- - 单次推理代价必须小

- - 预估的准确性不高

-  精排 

- - 给几百篇笔记打分

- - 单次推理代价很大

- - 预估的准确性更高

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618880844-d9eda898-c41b-4f42-a827-9e7814391a41.png)

-  精排模型 

- -  **前期融合**：先对所有特征做 concatenation，再输入神经网络 

- - - 这个网络叫 shared bottom，意思是它被多个任务共享

- -  线上推理代价大：如果有 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 篇候选笔记，整个大模型要做 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 次推理 

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618897140-fdd175e1-a329-48cd-ae7b-15bf2e0b20d4.png)

-  双塔模型（一种粗排模型）

- -  **后期融合**：把用户、物品特征分别输入不同的神经网络，不对用户、物品特征做融合 

- -  线上计算量小： 

- - - 用户塔只需要做一次线上推理，计算用户表征 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cbold%7Ba%7D)

- - - 物品表征 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?%5Cbold%7Bb%7D) 事先储存在向量数据库中，物品塔在线上不做推理

- -  后期融合模型不如前期融合模型准确 

- - - 预估准确性不如精排模型

- - - 后期融合模型用于召回，前期融合模型用于精排

### 粗排的三塔模型

小红书粗排用的三塔模型，效果介于双塔和精排之间。

参考文献：Zhe Wang et al. COLD: Towards the Next Generation of Pre-Ranking System. In DLP-KDD, 2020.

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618916372-f4b65f45-5835-4d74-aac4-3aa3bf9e90cb.png)

- 交叉特征：用户特征与物品特征做交叉

- 对 3 个塔输出的向量做 Concatenation 和 Cross（交叉）得到 1 个向量

- 与前期融合在最开始对各类特征做融合不同，三塔模型在塔输出的位置做融合

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618928907-7798d9a8-8c26-4183-b07f-29d4334fc526.png)

![img](https://cdn.nlark.com/yuque/0/2023/png/101969/1676618926246-1533cc54-f590-4a0b-9034-3113be4c7fcd.png)

-  有 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 个物品，模型上层需要做 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 次推理 

-  粗排推理的大部分计算量在模型上层 

- - 这个环节无法利用缓存节省计算量

- - 三塔模型节省的是对物品推理的计算量

-  三塔模型的推理 

- -  从多个数据源取特征： 

- - - 1 个用户的画像、统计特征

- - - ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 个物品的画像、统计特征

- -  用户塔：只做 1 次推理 

- -  物品塔：未命中缓存时需要做推理 

- -  交叉塔：必须做 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 次推理 

- -  上层网络做 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 次推理，给 ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?n) 个物品打分 

-  粗排模型的设计理念就是尽量减少推理的计算量，使得模型可以线上对几千篇笔记打分 